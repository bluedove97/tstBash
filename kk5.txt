#Multi-Cluster 구성

#ssh-keygen
ssh-keygen -t rsa
touch ~/.ssh/authorized_keys
chmod 755 ~/.ssh/authorized_keys


alias m1='ssh -i ~/.ssh/id_rsa kk-m1-ubuntu'
alias m2='ssh -i ~/.ssh/id_rsa kk-m2-ubuntu'
alias m3='ssh -i ~/.ssh/id_rsa kk-m3-ubuntu'
alias w1='ssh -i ~/.ssh/id_rsa kk-w1-ubuntu'
alias w2='ssh -i ~/.ssh/id_rsa kk-w2-ubuntu'
alias w3='ssh -i ~/.ssh/id_rsa kk-w3-ubuntu'
alias r1='ssh -i ~/.ssh/id_rsa kk-r1-ubuntu'
alias t1='ssh -i ~/.ssh/id_rsa kk-t1-ubuntu'

source .profile


#노드 정보
Host IP	Host Name		Usage

10.100.0.107	kk-m1-ubuntu
10.100.0.108	kk-m2-ubuntu
10.100.0.112	kk-m3-ubuntu
10.100.0.109	kk-w1-ubuntu
10.100.0.110	kk-w2-ubuntu
10.100.0.113	kk-w2-ubuntu
10.100.0.111	kk-r1-ubuntu
10.100.0.114	kk-t1-ubuntu


# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
Cluster3은 퍼블릭 설치
10.100.0.112	kk-m3-ubuntu	v1.24.9
10.100.0.113	kk-w2-ubuntu	v1.24.9

설치 완료
10.100.0.112:30880
192.168.219.167:30883
admin / P@88w0rd
admin / Kubesphere1


# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
Cluster1은 Air-gapped 설치
10.100.0.107	kk-m1-ubuntu	v1.22.12
10.100.0.109	kk-w1-ubuntu	v1.22.12
10.100.0.111	kk-r1-ubuntu


#kk-t1-ubuntu 에 있는 kk, artifact등을 master(kk-m1-ubuntu)로 복사
root@kk-t1-ubuntu:~# scp -rp kk kubekey-v3.0.7-linux-amd64.tar.gz root@kk-m1-ubuntu:/root
kk                                                                                           100%   75MB 138.6MB/s   00:00    
kubekey-v3.0.7-linux-amd64.tar.gz                                                            100%   34MB 157.8MB/s   00:00


#artifact.tar.gz를 master(kk-m1-ubuntu)로 복사
root@kk-t1-ubuntu:~# scp -rp artifact.tar.gz root@kk-m1-ubuntu:/root



# m1, w1으로 클러스터 구성
k8s v1.22.12
ks v3.3.2
./kk create config --with-kubesphere v3.3.2 --with-kubernetes v1.22.12 -f create-cluster.yaml

vi create-cluster.yaml



# 이제 클러스터 생성 해보자. 이미 하버에 푸시되어 있으니 스킵방식으로 진행
./kk create cluster -f create-cluster.yaml -a artifact.tar.gz --with-packages --skip-push-images



에러난다.
에러는 dockerhub.kubekey.local 에 로그인하려고 했는데, x509 certificate unknown authority 가 뜬 것
admin / Harbor12345 정보도 제대로 넣었으나 인증에러가 났다.


docker를 containerd로도 바꿔보고
이것저것 해보다가
docker login dockerhub.kubekey.local 도 같은에러로 안되는 것을 확인
kk-r1-ubuntu에서는 잘 되는것을 확인
kk-r1-ubuntu의  /etc/docker/certs.d 폴더를 각 m1, w1에 카피

kk-m1-ubuntu, kk-w1-ubuntu에서도 docker login dockerhub.kubekey.local 이 잘 되는것을 확인하고 다시 진행


# 인증서 처리 후 다시 시도
./kk create cluster -f create-cluster.yaml -a artifact.tar.gz --with-packages --skip-push-images

로그 쭉쭉
로그 쭉쭉

설치완료


10.100.0.107:30880
192.168.219.167:30880
admin / P@88w0rd
admin / Kubesphere1







# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
Cluster2는 퍼블릭 설치
10.100.0.108	kk-m2-ubuntu	v1.22.17
10.100.0.110	kk-w2-ubuntu	v1.22.17


root@kk-m2-ubuntu:~# kubectl get nodes -o wide
NAME           STATUS   ROLES                  AGE   VERSION    INTERNAL-IP    EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME
kk-m2-ubuntu   Ready    control-plane,master   11m   v1.22.17   10.100.0.108   <none>        Ubuntu 20.04.5 LTS   5.15.0-76-generic   containerd://1.6.4
kk-w2-ubuntu   Ready    worker                 11m   v1.22.17   10.100.0.110   <none>        Ubuntu 20.04.5 LTS   5.15.0-76-generic   containerd://1.6.4

설치 완료
10.100.0.108:30880
192.168.219.167:30882
admin / P@88w0rd
admin / Kubesphere1


























@ 에러

Waiting for all tasks to be completed ...
task network status is successful  (1/4)
task openpitrix status is successful  (2/4)
task monitoring status is successful  (3/4)
task multicluster status is failed  (4/4)
**************************************************
Collecting installation results ...


Task 'multicluster' failed:
******************************************************************************************************************************************************
{
  "counter": 65,
  "created": "2023-08-05T18:47:37.442093",
  "end_line": 67,
  "event": "runner_on_failed",
  "event_data": {
    "duration": 604.217412,
    "end": "2023-08-05T18:47:37.441981",
    "event_loop": null,
    "host": "localhost",
    "ignore_errors": null,
    "play": "localhost",
    "play_pattern": "localhost",
    "play_uuid": "1eecb4b2-5828-bd0f-b4ea-000000000005",
    "playbook": "/kubesphere/playbooks/multicluster.yaml",
    "playbook_uuid": "c298ebb8-d8f7-44f8-807c-60f13af918d5",
    "remote_addr": "127.0.0.1",
    "res": {
      "_ansible_no_log": false,
      "attempts": 10,
      "changed": true,
      "cmd": "/usr/local/bin/helm upgrade --install kubefed /kubesphere/kubesphere/kubefed/kubefed -f /kubesphere/kubesphere/kubefed/custom-values-kubefed.yaml --namespace kube-federation-system --wait --timeout 1800s\n",
      "delta": "0:00:00.132627",
      "end": "2023-08-06 03:47:37.419478",
      "invocation": {
        "module_args": {
          "_raw_params": "/usr/local/bin/helm upgrade --install kubefed /kubesphere/kubesphere/kubefed/kubefed -f /kubesphere/kubesphere/kubefed/custom-values-kubefed.yaml --namespace kube-federation-system --wait --timeout 1800s\n",
          "_uses_shell": true,
          "argv": null,
          "chdir": null,
          "creates": null,
          "executable": null,
          "removes": null,
          "stdin": null,
          "stdin_add_newline": true,
          "strip_empty_ends": true,
          "warn": true
        }
      },
      "msg": "non-zero return code",
      "rc": 1,
      "start": "2023-08-06 03:47:37.286851",
      "stderr": "Error: UPGRADE FAILED: another operation (install/upgrade/rollback) is in progress",
      "stderr_lines": [
        "Error: UPGRADE FAILED: another operation (install/upgrade/rollback) is in progress"
      ],
      "stdout": "",
      "stdout_lines": []
    },
    "resolved_action": "command",
    "role": "ks-multicluster",
    "start": "2023-08-05T18:37:33.224569",
    "task": "Kubefed | Initing kube-federation-system",
    "task_action": "command",
    "task_args": "",
    "task_path": "/kubesphere/installer/roles/ks-multicluster/tasks/main.yml:51",
    "task_uuid": "1eecb4b2-5828-bd0f-b4ea-00000000001f",
    "uuid": "06b5c04a-463a-42b4-b4f0-443fc8d82b0f"
  },
  "parent_uuid": "1eecb4b2-5828-bd0f-b4ea-00000000001f",
  "pid": 8895,
  "runner_ident": "multicluster",
  "start_line": 66,
  "stdout": "fatal: [localhost]: FAILED! => {\"attempts\": 10, \"changed\": true, \"cmd\": \"/usr/local/bin/helm upgrade --install kubefed /kubesphere/kubesphere/kubefed/kubefed -f /kubesphere/kubesphere/kubefed/custom-values-kubefed.yaml --namespace kube-federation-system --wait --timeout 1800s\\n\", \"delta\": \"0:00:00.132627\", \"end\": \"2023-08-06 03:47:37.419478\", \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-08-06 03:47:37.286851\", \"stderr\": \"Error: UPGRADE FAILED: another operation (install/upgrade/rollback) is in progress\", \"stderr_lines\": [\"Error: UPGRADE FAILED: another operation (install/upgrade/rollback) is in progress\"], \"stdout\": \"\", \"stdout_lines\": []}",
  "uuid": "06b5c04a-463a-42b4-b4f0-443fc8d82b0f"
}
******************************************************************************************************************************************************




# Cluster1에 Host Cluster 세팅

 kubectl edit cc ks-installer -n kubesphere-system
 clusterRole: host
 hostClusterName: hcluster1  <--- 요거 이름 대문자 특수문자 안되는듯
 
 kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l 'app in (ks-install, ks-installer)' -o jsonpath='{.items[0].metadata.name}') -f
	 




kube-federation-system         kubefed-admission-webhook-6f9f5dcbbf-mgscx         1/1     Running   0               3m31s
kube-federation-system         kubefed-controller-manager-77fbf668b8-t94kg        1/1     Running   0               2m59s
kubesphere-system              tower-786bb99f5d-cnzkj                             1/1     Running   0               3m41s

3개의 파드가 추가로 생기는데
Pending 된다.
메모리 부족인건지.. VM사양 부족인건지

그래서 
kubesphere-monitoring-system   prometheus-k8s-0                                   0/2     Pending
를 죽여서 위의 3개 파드는 생성되고
prometheus-k8s-0 는 Pending되게 만들었다.

prometheus-k8s-0을 지우니, 노드, 파드 현황이 안보여서
kubesphere-monitoring-system   alertmanager-main-0                                0/2     Pending   0
를 지우는것으로 해봄




# Cluster2에 Member Cluster 세팅
멤버설정할 때는 Pending 되는 것은 없더라
host 설정과는 다르게 kube-federation-system 과 tower pod가 추가되거나 하진 않아서 그런 것 같음

kubectl edit cc ks-installer -n kubesphere-system
jwtSecret: 1bCScmByJYU13hm6MwIBnEwCuQ1Ofwa8
clusterRole: member





# Cluster3에 Member Cluster 세팅
Cluster3는 다른 PC에 설정함. 노트북의 사양이 딸려서 3번째 클러스터를 올리는 것은 불가능하더라
Cluster3 역시 VM으로 올렸고
Cluster1 master에서 Cluster3 master로 접근 할 수 있게 port-forwarding 처리 함


kubectl edit cc ks-installer -n kubesphere-system
jwtSecret: 1bCScmByJYU13hm6MwIBnEwCuQ1Ofwa8
clusterRole: member



Start installing monitoring
Start installing multicluster
Start installing openpitrix
Start installing network
**************************************************
Waiting for all tasks to be completed ...
task network status is successful  (1/4)
task openpitrix status is successful  (2/4)
task multicluster status is successful  (3/4)
task monitoring status is successful  (4/4)
**************************************************
Collecting installation results ...
#####################################################
###              Welcome to KubeSphere!           ###
#####################################################

Console: http://10.100.0.112:30880
Account: admin
Password: P@88w0rd
NOTES：
  1. After you log into the console, please check the
     monitoring status of service components in
     "Cluster Management". If any service is not
     ready, please wait patiently until all components 
     are up and running.
  2. Please change the default password after login.

#####################################################
https://kubesphere.io             2023-08-06 16:14:55
####################################################



# 이제 Add Cluster 해보자






Get "https://192.168.219.146:6443/api/v1/namespaces/kube-system?timeout=10s": x509: certificate is valid for 10.233.0.1, 10.100.0.112, 127.0.0.1, 10.100.0.113, not 192.168.219.146

악.. 서로 다른 네트워크 대역대여서
Cluster3의 kubeconfig 가져올때 에러가 난다.

요걸 참고해서
https://happycloud-lee.tistory.com/235
kubeconfig에 허용 ip를 추가하자


된다.. 눈물 ㅠㅠ







******************************************************************************************************************************************************


# Cluster2(mcluster1)의 버전을 v1.22.17 에서 v1.24.9로 upgrade

업그레이드를 위해 도커를 설치하자. kk-m2-ubuntu와 kk-w2-ubuntu에 각각 설치

apt-get update
apt-get install ca-certificates gnupg lsb-release

Add Docker’s official GPG key
  sudo mkdir -p /etc/apt/keyrings
  curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg

Set up the repository:
  echo \
    "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
    $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

Install Docker Engine
  sudo apt-get update
  sudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin

 
# cluster 업그레이드. kk-m2-ubuntu에서 실행
# kubekey로 kubernetes의 버전을 v1.22.17 에서 v1.24.9 로 업그레이드


./kk create config --from-cluster 로 구성 파일 생성
mv sample.yaml upgrade-cluster.yaml

vi upgrade-cluster.yaml  <---- ssh 정보, 버전정보, etcd 정보 수정하고 


./kk upgrade --with-kubernetes v1.24.9  -f upgrade-cluster.yaml


어어어...에러?? 
panic: illegal version string "24..5"

goroutine 198 [running]:
k8s.io/apimachinery/pkg/util/version.MustParseSemantic({0xc00096a970?, 0x6?})
	k8s.io/apimachinery@v0.25.4/pkg/util/version/version.go:119 +0x45
github.com/kubesphere/kubekey/v3/cmd/kk/pkg/bootstrap/confirm.(*UpgradeConfirm).Execute(0xc0001c2af8, {0x27545f0, 0xc000331200})
	github.com/kubesphere/kubekey/v3/cmd/kk/pkg/bootstrap/confirm/tasks.go:218 +0xddf
github.com/kubesphere/kubekey/v3/cmd/kk/pkg/core/task.(*LocalTask).ExecuteWithRetry(0xc0000cafd0, {0x27545f0, 0xc000331200}, {0x275a6f8, 0xc00022f980})
	github.com/kubesphere/kubekey/v3/cmd/kk/pkg/core/task/local_task.go:205 +0x126
github.com/kubesphere/kubekey/v3/cmd/kk/pkg/core/task.(*LocalTask).Run(0xc0000cafd0, {0x27545f0, 0xc000331200}, {0x275a6f8?, 0xc00022f980}, 0x0?)
	github.com/kubesphere/kubekey/v3/cmd/kk/pkg/core/task/local_task.go:159 +0x225
created by github.com/kubesphere/kubekey/v3/cmd/kk/pkg/core/task.(*LocalTask).RunWithTimeout
	github.com/kubesphere/kubekey/v3/cmd/kk/pkg/core/task/local_task.go:121 +0x172


도커때문인가 최신 도커로 설치했을 때 24.05 버전이었음
도커 다시 지우고 20.10 버전으로 다시 설치해보자
24.05 버전.. 왠지 찝찝하다


도커 설치가능버전 확인
apt-cache madison docker-ce

20.10의 마지막버전으로 해보자

apt-get install docker-ce=5:20.10.24~3-0~ubuntu-focal docker-ce-cli=5:20.10.24~3-0~ubuntu-focal containerd.io docker-compose-plugin

docker --version 하니 20.10 으로 나오고


업그레이드 재도전
./kk upgrade --with-kubernetes v1.24.9  -f upgrade-cluster.yaml


아까와는 다르게 진행되는 듯.



